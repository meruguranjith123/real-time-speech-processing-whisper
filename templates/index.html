<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Speech Processing Demo</title>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
            color: #333;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 1.1em;
            opacity: 0.9;
        }

        .content {
            padding: 30px;
        }

        .controls {
            text-align: center;
            margin-bottom: 30px;
        }

        .btn {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            padding: 15px 40px;
            font-size: 1.2em;
            border-radius: 50px;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
            margin: 0 10px;
            font-weight: bold;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 20px rgba(102, 126, 234, 0.4);
        }

        .btn:active {
            transform: translateY(0);
        }

        .btn.stop {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        }

        .btn.final-output {
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        .status {
            text-align: center;
            margin: 20px 0;
            font-size: 1.1em;
            font-weight: bold;
        }

        .status.recording {
            color: #f5576c;
            animation: pulse 1.5s infinite;
        }

        .status.idle {
            color: #667eea;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .display-section {
            margin: 30px 0;
        }

        .display-section h2 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.5em;
            border-bottom: 2px solid #667eea;
            padding-bottom: 10px;
        }

        .text-display {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 10px;
            padding: 20px;
            min-height: 100px;
            font-size: 1.2em;
            line-height: 1.6;
            margin-bottom: 20px;
        }

        .cleaned-text {
            background: #e8f5e9;
            border-color: #4caf50;
            color: #2e7d32;
        }

        .stutters-list {
            background: #fff3e0;
            border-color: #ff9800;
            padding: 15px;
            border-radius: 10px;
            margin-top: 15px;
        }

        .stutters-list h3 {
            color: #f57c00;
            margin-bottom: 10px;
        }

        .stutter-item {
            background: white;
            padding: 8px 15px;
            margin: 5px 0;
            border-radius: 5px;
            border-left: 4px solid #ff9800;
        }

        .predictions {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 15px;
            margin-top: 15px;
        }

        .prediction-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            transition: transform 0.2s;
        }

        .prediction-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.2);
        }

        .prediction-card h4 {
            margin-bottom: 10px;
            font-size: 0.9em;
            opacity: 0.9;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .prediction-text {
            font-size: 1.1em;
            line-height: 1.5;
        }

        .audio-visualizer {
            width: 100%;
            height: 100px;
            background: #f8f9fa;
            border-radius: 10px;
            margin: 20px 0;
            display: flex;
            align-items: center;
            justify-content: center;
            border: 2px solid #e9ecef;
        }

        .visualizer-bar {
            width: 4px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            margin: 0 2px;
            border-radius: 2px;
            transition: height 0.1s;
        }

        .info-box {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
        }

        .info-box p {
            margin: 5px 0;
            color: #1565c0;
        }

        /* Modal Styles */
        .modal-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.7);
            z-index: 1000;
            overflow-y: auto;
            animation: fadeIn 0.3s;
        }

        .modal-overlay.show {
            display: flex;
            justify-content: center;
            align-items: flex-start;
            padding: 20px;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        .modal-content {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 900px;
            width: 100%;
            margin: 40px auto;
            padding: 30px;
            animation: slideDown 0.3s;
            position: relative;
        }

        @keyframes slideDown {
            from {
                transform: translateY(-50px);
                opacity: 0;
            }
            to {
                transform: translateY(0);
                opacity: 1;
            }
        }

        .modal-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 2px solid #e9ecef;
        }

        .modal-header h2 {
            color: #667eea;
            margin: 0;
            font-size: 2em;
        }

        .modal-close {
            background: #f5576c;
            color: white;
            border: none;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            cursor: pointer;
            font-size: 1.5em;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: transform 0.2s;
        }

        .modal-close:hover {
            transform: scale(1.1);
        }

        .modal-section {
            margin: 25px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
            border-left: 4px solid #667eea;
        }

        .modal-section h3 {
            color: #667eea;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .modal-section-content {
            background: white;
            padding: 15px;
            border-radius: 8px;
            min-height: 50px;
            line-height: 1.6;
        }

        .modal-stutters {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }

        .modal-stutter-badge {
            background: #fff3e0;
            color: #f57c00;
            padding: 8px 15px;
            border-radius: 20px;
            border: 2px solid #ff9800;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üé§ Real-Time Speech Processing</h1>
            <p>Powered by Whisper AI ‚Ä¢ Stuttering Detection ‚Ä¢ Next Sentence Prediction</p>
        </div>

        <div class="content">
            <div class="controls">
                <button id="startBtn" class="btn">Start Recording</button>
                <button id="stopBtn" class="btn stop" disabled>Stop Recording</button>
                <button id="finalOutputBtn" class="btn final-output" disabled title="View Final Output">
                    üìã Final Output
                </button>
            </div>

            <div id="status" class="status idle">Ready to record</div>

            <div class="audio-visualizer" id="visualizer">
                <div id="visualizerBars"></div>
            </div>

            <div class="display-section">
                <h2>üìù Raw Transcription</h2>
                <div id="rawText" class="text-display">Waiting for audio input...</div>
            </div>

            <div class="display-section">
                <h2>‚ú® Cleaned Text (Stuttering Removed)</h2>
                <div id="cleanedText" class="text-display cleaned-text">Waiting for audio input...</div>
                <div id="stuttersContainer" style="display: none;">
                    <div class="stutters-list">
                        <h3>üîç Detected Stutter Patterns:</h3>
                        <p style="font-size: 0.9em; color: #666; margin-bottom: 10px;">
                            Format: <strong>word - count</strong> (e.g., "the - 2" means "the" was repeated 2 times)
                        </p>
                        <div id="stuttersList"></div>
                    </div>
                </div>
            </div>

            <div class="display-section">
                <h2>üîÆ Predicted Next Sentences</h2>
                <div id="predictions" class="predictions">
                    <div class="prediction-card">
                        <h4>Prediction 1</h4>
                        <div class="prediction-text">Start speaking to see predictions...</div>
                    </div>
                </div>
            </div>

            <div class="info-box">
                <p><strong>How it works:</strong></p>
                <p>1. Click "Start Recording" to begin capturing audio</p>
                <p>2. Speak naturally - the system will transcribe in real-time</p>
                <p>3. Stutters and repetitions are automatically detected and cleaned</p>
                <p>4. Possible next sentences are predicted based on your current speech</p>
                <p>5. Click "Final Output" after speaking to see a complete summary</p>
            </div>
        </div>
    </div>

    <!-- Final Output Modal -->
    <div id="finalOutputModal" class="modal-overlay">
        <div class="modal-content">
            <div class="modal-header">
                <h2>üìã Final Output Summary</h2>
                <button class="modal-close" id="closeModal">&times;</button>
            </div>

            <div class="modal-section">
                <h3>üìù Raw Audio Transcription</h3>
                <div id="modalRawText" class="modal-section-content">No audio captured yet.</div>
            </div>

            <div class="modal-section">
                <h3>‚ú® Cleaned Text (Stuttering Removed)</h3>
                <div id="modalCleanedText" class="modal-section-content">No cleaned text available.</div>
            </div>

            <div class="modal-section">
                <h3>üîç Detected Stutter Patterns</h3>
                <div id="modalStutters" class="modal-section-content">
                    <div class="modal-stutters" id="modalStuttersList">
                        <span style="color: #999;">No stutters detected.</span>
                    </div>
                </div>
            </div>

            <div class="modal-section">
                <h3>üîÆ Predicted Next Sentences</h3>
                <div id="modalPredictions" class="modal-section-content">
                    <div id="modalPredictionsList" style="color: #999;">No predictions available.</div>
                </div>
            </div>
        </div>
    </div>

    <script>
        const socket = io();
        let mediaRecorder;
        let audioContext;
        let analyser;
        let dataArray;
        let isRecording = false;
        let animationFrame;
        let audioChunks = []; // Accumulate audio chunks
        let accumulatedAudio = null; // For processing accumulated audio
        let processingInterval = null; // Interval for periodic processing

        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const finalOutputBtn = document.getElementById('finalOutputBtn');
        const status = document.getElementById('status');
        const rawText = document.getElementById('rawText');
        const cleanedText = document.getElementById('cleanedText');
        const stuttersContainer = document.getElementById('stuttersContainer');
        const stuttersList = document.getElementById('stuttersList');
        const predictions = document.getElementById('predictions');
        const visualizer = document.getElementById('visualizerBars');
        
        // Modal elements
        const finalOutputModal = document.getElementById('finalOutputModal');
        const closeModal = document.getElementById('closeModal');
        const modalRawText = document.getElementById('modalRawText');
        const modalCleanedText = document.getElementById('modalCleanedText');
        const modalStuttersList = document.getElementById('modalStuttersList');
        const modalPredictionsList = document.getElementById('modalPredictionsList');
        
        // Store final results
        let finalResults = {
            rawText: '',
            cleanedText: '',
            stutters: [],
            predictions: []
        };
        
        // Accumulate raw text for real-time display
        let accumulatedRawText = '';
        
        // Accumulate all detected stutters (don't replace, keep adding)
        let allDetectedStutters = [];

        // Initialize visualizer bars
        function initVisualizer() {
            visualizer.innerHTML = '';
            for (let i = 0; i < 50; i++) {
                const bar = document.createElement('div');
                bar.className = 'visualizer-bar';
                bar.style.height = '10px';
                visualizer.appendChild(bar);
            }
        }

        initVisualizer();

        // Update visualizer
        function updateVisualizer() {
            if (!analyser || !isRecording) return;

            dataArray = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(dataArray);

            const bars = visualizer.children;
            const step = Math.floor(dataArray.length / bars.length);

            for (let i = 0; i < bars.length; i++) {
                const value = dataArray[i * step] || 0;
                const height = (value / 255) * 100;
                bars[i].style.height = Math.max(height, 10) + 'px';
            }

            if (isRecording) {
                animationFrame = requestAnimationFrame(updateVisualizer);
            }
        }

        // Start recording
        startBtn.addEventListener('click', async () => {
            try {
                // Request microphone access with specific constraints
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 16000  // Use 16kHz to match Whisper requirements
                    } 
                });
                
                console.log('Microphone access granted');
                console.log('Audio tracks:', stream.getAudioTracks());
                
                // Set up audio context for visualization and PCM capture
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });
                const source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                analyser.smoothingTimeConstant = 0.8;
                source.connect(analyser);
                
                // Initialize PCM buffer on window object
                window.pcmBuffer = [];
                
                // Create ScriptProcessorNode for PCM audio capture (deprecated but widely supported)
                // Alternative: Use AudioWorklet if available, but ScriptProcessorNode is more compatible
                const bufferSize = 4096;
                const scriptProcessor = audioContext.createScriptProcessor(bufferSize, 1, 1);
                
                // Function to send accumulated PCM audio
                const sendPCMAudio = () => {
                    if (!window.pcmBuffer || window.pcmBuffer.length === 0) return;
                    
                    // Combine all buffers
                    const totalLength = window.pcmBuffer.reduce((sum, buf) => sum + buf.length, 0);
                    const combined = new Int16Array(totalLength);
                    let offset = 0;
                    for (const buf of window.pcmBuffer) {
                        combined.set(buf, offset);
                        offset += buf.length;
                    }
                    
                    // Convert to base64 - use a more efficient method for large arrays
                    const uint8Array = new Uint8Array(combined.buffer);
                    let binary = '';
                    const chunkSize = 8192; // Process in chunks to avoid stack overflow
                    for (let i = 0; i < uint8Array.length; i += chunkSize) {
                        binary += String.fromCharCode.apply(null, uint8Array.subarray(i, i + chunkSize));
                    }
                    const base64Audio = btoa(binary);
                    
                    console.log(`Sending PCM audio: ${combined.length} samples (${(combined.length / 16000).toFixed(2)}s)`);
                    
                    // Update status to show processing
                    status.textContent = 'üîÑ Processing audio...';
                    
                    // Send to server
                    socket.emit('audio_data', {
                        data: base64Audio,
                        sample_rate: 16000,
                        format: 'pcm'
                    });
                    
                    // Clear buffer
                    window.pcmBuffer = [];
                };
                
                scriptProcessor.onaudioprocess = (event) => {
                    if (!isRecording) return;
                    
                    const inputData = event.inputBuffer.getChannelData(0);
                    // Convert Float32 to Int16 PCM
                    const pcm16 = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        // Clamp to [-1, 1] and convert to 16-bit integer
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }
                    
                    // Add to buffer
                    window.pcmBuffer.push(pcm16);
                    
                    // Send audio every ~2 seconds (bufferSize samples at 16kHz = ~0.25s per chunk, so 8 chunks = 2s)
                    if (window.pcmBuffer.length >= 8) {
                        sendPCMAudio();
                    }
                };
                
                source.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);
                
                // Store scriptProcessor for cleanup
                window.scriptProcessor = scriptProcessor;
                
                // Also set up periodic sending (every 3 seconds) as backup
                processingInterval = setInterval(() => {
                    if (window.pcmBuffer && window.pcmBuffer.length > 0 && isRecording) {
                        sendPCMAudio();
                    }
                }, 3000);

                isRecording = true;
                startBtn.disabled = true;
                stopBtn.disabled = false;
                finalOutputBtn.disabled = true; // Disable until we have results
                status.textContent = 'üî¥ Recording...';
                status.className = 'status recording';
                
                // Reset stutters list when starting new recording
                allDetectedStutters = [];
                stuttersContainer.style.display = 'none';

                // Process accumulated audio every 3 seconds to ensure we send data
                processingInterval = setInterval(async () => {
                    if (audioChunks.length > 0 && isRecording) {
                        await processAccumulatedAudio();
                    }
                }, 3000);

                updateVisualizer();

            } catch (error) {
                console.error('Error accessing microphone:', error);
                alert('Error accessing microphone. Please check permissions.');
            }
        });

        // Stop recording
        stopBtn.addEventListener('click', async () => {
            // Clear processing interval
            if (processingInterval) {
                clearInterval(processingInterval);
                processingInterval = null;
            }
            
            // Send any remaining PCM audio
            if (window.pcmBuffer && window.pcmBuffer.length > 0) {
                // Send remaining audio
                const totalLength = window.pcmBuffer.reduce((sum, buf) => sum + buf.length, 0);
                const combined = new Int16Array(totalLength);
                let offset = 0;
                for (const buf of window.pcmBuffer) {
                    combined.set(buf, offset);
                    offset += buf.length;
                }
                // Convert to base64 efficiently
                const uint8Array = new Uint8Array(combined.buffer);
                let binary = '';
                const chunkSize = 8192;
                for (let i = 0; i < uint8Array.length; i += chunkSize) {
                    binary += String.fromCharCode.apply(null, uint8Array.subarray(i, i + chunkSize));
                }
                const base64Audio = btoa(binary);
                socket.emit('audio_data', {
                    data: base64Audio,
                    sample_rate: 16000,
                    format: 'pcm'
                });
            }
            
            // Disconnect script processor
            if (window.scriptProcessor) {
                window.scriptProcessor.disconnect();
                window.scriptProcessor = null;
            }
            
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
            }

            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close();
            }

            if (animationFrame) {
                cancelAnimationFrame(animationFrame);
            }

            isRecording = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;
            status.textContent = 'Ready to record';
            status.className = 'status idle';
            audioChunks = []; // Clear chunks
            if (window.pcmBuffer) window.pcmBuffer = [];

            // Reset visualizer
            const bars = visualizer.children;
            for (let bar of bars) {
                bar.style.height = '10px';
            }

            socket.emit('reset');
            
            // Store final results before resetting
            finalResults.rawText = accumulatedRawText || rawText.textContent;
            finalResults.cleanedText = cleanedText.textContent;
            
            // Store all accumulated stutters (use the accumulated list)
            if (allDetectedStutters.length > 0) {
                finalResults.stutters = [...allDetectedStutters];
            } else if (stuttersList && stuttersList.children.length > 0) {
                finalResults.stutters = Array.from(stuttersList.children).map(item => {
                    const strong = item.querySelector('strong');
                    return strong ? strong.textContent.trim() : item.textContent.trim();
                }).filter(s => s);
            } else {
                finalResults.stutters = [];
            }
            
            // Extract predictions
            if (predictions && predictions.children.length > 0) {
                finalResults.predictions = Array.from(predictions.children).map(card => {
                    const predText = card.querySelector('.prediction-text');
                    return predText ? predText.textContent.trim() : '';
                }).filter(p => p && p !== 'Start speaking to see predictions...');
            } else {
                finalResults.predictions = [];
            }
            
            // Enable Final Output button if we have results
            if (finalResults.rawText && finalResults.rawText !== 'Waiting for audio input...' && 
                finalResults.rawText !== 'Processing... (no speech detected yet)') {
                finalOutputBtn.disabled = false;
            }
            
            // Reset accumulated text and stutters
            if (typeof accumulatedRawText !== 'undefined') {
                accumulatedRawText = '';
            }
            allDetectedStutters = []; // Reset stutters list for next recording
            rawText.textContent = 'Waiting for audio input...';
            cleanedText.textContent = 'Waiting for audio input...';
            stuttersContainer.style.display = 'none'; // Hide stutters container
        });
        
        // Final Output button click handler
        finalOutputBtn.addEventListener('click', () => {
            // Update modal content with final results
            modalRawText.textContent = finalResults.rawText || 'No raw audio captured.';
            modalRawText.style.color = finalResults.rawText ? '#333' : '#999';
            
            modalCleanedText.textContent = finalResults.cleanedText || 'No cleaned text available.';
            modalCleanedText.style.color = finalResults.cleanedText ? '#2e7d32' : '#999';
            
            // Display stutters
            if (finalResults.stutters && finalResults.stutters.length > 0) {
                modalStuttersList.innerHTML = finalResults.stutters.map(stutter => {
                    const formatted = stutter.includes(' - ') ? stutter : stutter;
                    return `<span class="modal-stutter-badge">${formatted}</span>`;
                }).join('');
            } else {
                modalStuttersList.innerHTML = '<span style="color: #999;">No stutters detected.</span>';
            }
            
            // Display predictions
            if (finalResults.predictions && finalResults.predictions.length > 0) {
                modalPredictionsList.innerHTML = finalResults.predictions.map((pred, index) => `
                    <div style="margin: 10px 0; padding: 15px; background: #f8f9fa; border-radius: 8px; border-left: 4px solid #667eea;">
                        <strong style="color: #667eea;">Prediction ${index + 1}:</strong>
                        <div style="margin-top: 8px; color: #333;">${pred}</div>
                    </div>
                `).join('');
            } else {
                modalPredictionsList.innerHTML = '<span style="color: #999;">No predictions available.</span>';
            }
            
            // Show modal
            finalOutputModal.classList.add('show');
        });
        
        // Close modal handlers
        closeModal.addEventListener('click', () => {
            finalOutputModal.classList.remove('show');
        });
        
        finalOutputModal.addEventListener('click', (e) => {
            if (e.target === finalOutputModal) {
                finalOutputModal.classList.remove('show');
            }
        });
        
        // Close modal with Escape key
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape' && finalOutputModal.classList.contains('show')) {
                finalOutputModal.classList.remove('show');
            }
        });

        // Handle transcription results
        socket.on('transcription_result', (result) => {
            console.log('Received transcription result:', result);
            
            // Accumulate raw text (append new transcription to existing)
            if (result.raw_text && result.raw_text.trim()) {
                // If we have accumulated text, append with space
                if (accumulatedRawText && !accumulatedRawText.endsWith(' ')) {
                    accumulatedRawText += ' ';
                }
                accumulatedRawText += result.raw_text;
                rawText.textContent = accumulatedRawText;
                rawText.style.color = '#333';
            } else if (result.raw_text === '') {
                // Only show "Processing..." if we have no accumulated text
                if (!accumulatedRawText) {
                    rawText.textContent = 'Processing... (no speech detected yet)';
                    rawText.style.color = '#999';
                }
            }

            // Update cleaned text (accumulate intelligently)
            if (result.cleaned_text && result.cleaned_text.trim()) {
                // For cleaned text, accumulate but avoid duplicates
                if (cleanedText.textContent && cleanedText.textContent !== 'Waiting for audio input...' && 
                    cleanedText.textContent !== 'Processing... (no speech detected yet)') {
                    // Append if new content doesn't already exist
                    if (!cleanedText.textContent.includes(result.cleaned_text)) {
                        cleanedText.textContent += ' ' + result.cleaned_text;
                    }
                } else {
                    cleanedText.textContent = result.cleaned_text;
                }
                cleanedText.style.color = '#2e7d32';
            } else if (result.cleaned_text === '' && !cleanedText.textContent.includes('Waiting') && 
                       !cleanedText.textContent.includes('Processing')) {
                // Keep existing cleaned text if new result is empty
            } else if (result.cleaned_text === '') {
                cleanedText.textContent = 'Processing... (no speech detected yet)';
                cleanedText.style.color = '#999';
            }
            
            // Update status back to recording after processing
            if (isRecording) {
                status.textContent = 'üî¥ Recording...';
                status.className = 'status recording';
            }

            // Display stutters with pattern format (word - count) - accumulate all stutters continuously
            if (result.stutters && result.stutters.length > 0) {
                // Add new stutters to the accumulated list (avoid duplicates)
                result.stutters.forEach(stutter => {
                    const formatted = stutter.includes(' - ') ? stutter : stutter;
                    // Check if this stutter pattern already exists
                    if (!allDetectedStutters.includes(formatted)) {
                        allDetectedStutters.push(formatted);
                    }
                });
                
                // Always show the stutters container if we have any stutters
                if (allDetectedStutters.length > 0) {
                    stuttersContainer.style.display = 'block';
                    stuttersList.innerHTML = allDetectedStutters.map(stutter => 
                        `<div class="stutter-item"><strong>${stutter}</strong></div>`
                    ).join('');
                }
            } else if (allDetectedStutters.length > 0) {
                // Keep showing accumulated stutters even if current result has none
                stuttersContainer.style.display = 'block';
                stuttersList.innerHTML = allDetectedStutters.map(stutter => 
                    `<div class="stutter-item"><strong>${stutter}</strong></div>`
                ).join('');
            } else {
                stuttersContainer.style.display = 'none';
            }

            // Display predictions (based on raw stuttered audio)
            if (result.predictions && result.predictions.length > 0) {
                predictions.innerHTML = result.predictions.map((pred, index) => `
                    <div class="prediction-card">
                        <h4>Prediction ${index + 1}</h4>
                        <div class="prediction-text">${pred}</div>
                    </div>
                `).join('');
            }
        });

        // Handle errors
        socket.on('error', (error) => {
            console.error('Server error:', error);
            alert('Error processing audio: ' + error.message);
        });

        // Connection status
        socket.on('connect', () => {
            console.log('Connected to server');
            if (status && !isRecording) {
                status.textContent = 'Ready to record (Connected)';
            }
        });

        socket.on('disconnect', () => {
            console.log('Disconnected from server');
            if (status) {
                status.textContent = 'Disconnected from server';
                status.className = 'status idle';
            }
        });

        socket.on('connect_error', (error) => {
            console.error('Connection error:', error);
            alert('Failed to connect to server. Please make sure the server is running.');
        });
    </script>
</body>
</html>

